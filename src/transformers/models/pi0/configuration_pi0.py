#                ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨
#           This file was automatically generated from src/transformers/models/pi0/modular_pi0.py.
#               Do NOT edit this file manually as any edits will be overwritten by the generation of
#             the file from the modular. If any change should be done, please apply the change to the
#                          modular_pi0.py file directly. One of our CI enforces this.
#                ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨
# Copyright 2025 Physical Intelligence and The HuggingFace Inc. team. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
from ...configuration_utils import PreTrainedConfig
from ..auto import CONFIG_MAPPING, AutoConfig
from ..siglip import SiglipVisionConfig


class PI0Config(PreTrainedConfig):
    r"""
    Configuration class for PI0.

    PI0 is a robot action prediction model that combines a PaliGemma VLM backbone
    with an action expert Gemma model. It uses flow matching for continuous action generation.

    Args:
        vision_config (`dict`, *optional*):
            Configuration for the vision encoder (SiglipVisionModel).
        text_config (`dict`, *optional*):
            Configuration for the language model (GemmaModel).
        expert_config (`dict`, *optional*):
            Configuration for the action expert (GemmaModel). Defaults to a Gemma 300M variant.
        chunk_size (`int`, *optional*, defaults to 50):
            Number of action steps to predict per chunk.
        max_state_dim (`int`, *optional*, defaults to 32):
            Maximum state vector dimension (shorter vectors are zero-padded).
        max_action_dim (`int`, *optional*, defaults to 32):
            Maximum action vector dimension (shorter vectors are zero-padded).
        num_inference_steps (`int`, *optional*, defaults to 10):
            Number of denoising steps during inference.
        time_sampling_beta_alpha (`float`, *optional*, defaults to 1.5):
            Alpha parameter for Beta distribution used to sample diffusion time during training.
        time_sampling_beta_beta (`float`, *optional*, defaults to 1.0):
            Beta parameter for Beta distribution used to sample diffusion time during training.
        time_sampling_scale (`float`, *optional*, defaults to 0.999):
            Scale factor for sampled time values.
        time_sampling_offset (`float`, *optional*, defaults to 0.001):
            Offset added to sampled time values.
        min_period (`float`, *optional*, defaults to 4e-3):
            Minimum period for sinusoidal time embedding.
        max_period (`float`, *optional*, defaults to 4.0):
            Maximum period for sinusoidal time embedding.

    Example:
    ```python
    >>> from transformers import PI0ForConditionalGeneration, PI0Config

    >>> config = PI0Config()
    >>> model = PI0ForConditionalGeneration(config)
    ```
    """

    model_type = "pi0"
    attribute_map = {
        "image_token_id": "image_token_index",
    }
    sub_configs = {
        "text_config": AutoConfig,
        "vision_config": SiglipVisionConfig,
        "expert_config": AutoConfig,
    }
    keys_to_ignore_at_inference = ["past_key_values"]

    def __init__(
        self,
        vision_config=None,
        text_config=None,
        expert_config=None,
        image_token_index=256000,
        vocab_size=257152,
        projection_dim=2048,
        hidden_size=2048,
        tie_word_embeddings: bool | None = True,
        chunk_size=50,
        max_state_dim=32,
        max_action_dim=32,
        num_inference_steps=10,
        time_sampling_beta_alpha=1.5,
        time_sampling_beta_beta=1.0,
        time_sampling_scale=0.999,
        time_sampling_offset=0.001,
        min_period=4e-3,
        max_period=4.0,
        **kwargs,
    ):
        if vision_config is None:
            vision_config = {
                "hidden_size": 1152,
                "intermediate_size": 4304,
                "num_hidden_layers": 27,
                "num_attention_heads": 16,
                "patch_size": 14,
                "image_size": 224,
                "vision_use_head": False,
            }
        self.image_token_index = image_token_index
        self.projection_dim = projection_dim
        self.hidden_size = hidden_size
        self.vision_config = vision_config
        self.tie_word_embeddings = tie_word_embeddings
        self.is_encoder_decoder = False

        if isinstance(self.vision_config, dict):
            vision_config["model_type"] = vision_config.get("model_type", "siglip_vision_model")
            self.vision_config = CONFIG_MAPPING[vision_config["model_type"]](**vision_config)
        elif vision_config is None:
            self.vision_config = CONFIG_MAPPING["siglip_vision_model"](
                intermediate_size=4096,
                hidden_size=1152,
                patch_size=14,
                image_size=224,
                num_hidden_layers=27,
                num_attention_heads=16,
                vocab_size=257152,
                vision_use_head=False,
            )

        self.text_config = text_config
        if isinstance(self.text_config, dict):
            text_config["model_type"] = text_config.get("model_type", "gemma")
            self.text_config = CONFIG_MAPPING[text_config["model_type"]](**text_config)
        elif text_config is None:
            self.text_config = CONFIG_MAPPING["gemma"](
                hidden_size=2048,
                num_hidden_layers=18,
                intermediate_size=16384,
                num_attention_heads=8,
                num_key_value_heads=1,
                is_encoder_decoder=False,
                vocab_size=vocab_size,
            )

        # BC: `use_bidirectional_attention` was originally unset in PI01 (backbone = Gemma1) AND PI02
        # (backbone = Gemma2). Both PI0s want to default to True.
        if self.text_config.use_bidirectional_attention is None:
            self.text_config.use_bidirectional_attention = True

        self.text_config.num_image_tokens = (self.vision_config.image_size // self.vision_config.patch_size) ** 2
        self.vision_config.projection_dim = projection_dim
        super().__init__(**kwargs)

        self.chunk_size = chunk_size
        self.max_state_dim = max_state_dim
        self.max_action_dim = max_action_dim
        self.num_inference_steps = num_inference_steps
        self.time_sampling_beta_alpha = time_sampling_beta_alpha
        self.time_sampling_beta_beta = time_sampling_beta_beta
        self.time_sampling_scale = time_sampling_scale
        self.time_sampling_offset = time_sampling_offset
        self.min_period = min_period
        self.max_period = max_period

        if isinstance(expert_config, dict):
            expert_config["model_type"] = expert_config.get("model_type", "gemma")
            self.expert_config = AutoConfig.for_model(**expert_config)
        elif expert_config is None:
            self.expert_config = AutoConfig.for_model(
                "gemma",
                hidden_size=1024,
                num_hidden_layers=18,
                intermediate_size=4096,
                num_attention_heads=8,
                num_key_value_heads=1,
                head_dim=256,
                vocab_size=self.text_config.vocab_size,
            )
        else:
            self.expert_config = expert_config

        self.expert_config.is_causal = False
        self.expert_config.use_bidirectional_attention = True


__all__ = ["PI0Config"]
